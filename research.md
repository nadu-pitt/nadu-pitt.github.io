---
layout: page
title: Research
---


Our research goal is to improve human performance, safety, and well-being by applying human factors, data analytics, and cognitive science to the analysis, design, and evaluation of the intelligent systems. Research topics include: 

<a role="button" href="#bm1" class="btn btn-primary btn-md">Human Factors in Intelligent Transportation Systems </a>

<a role="button" href="#bm2" class="btn btn-primary btn-md">Human-Robot Interaction </a>

<a role="button" href="#bm3" class="btn btn-primary btn-md">Human Behavior Modeling </a>

<a role="button" href="#bm4" class="btn btn-primary btn-md">Trust and Situational Awareness in Human-Automation Teaming</a>



<p>&nbsp;</p>

---
## Human Factors in Intelligent Transportation Systems {#bm1}
<p></p>
Intelligent transportation systems with connected and automated vehicles (CAVs) have the potential to provide our society with more fuel-efficient driving, reduce driving-related injuries and deaths, and reshape transportation and logistics. While CAVs are not completely ready on the road, it is necessary to study human factors in intelligent transportation systems to improve human performance, safety, and well-being. Our studies investigate drivers' behavioral and physiological responses in various driving environments. We also design and evaluate human-machine interfaces (HMIs) to improve user experience and driving safety in intelligent transportation systems. 
<!-- While we are a long way from the fully automated vehicles, automated driving features at SAE Level 3, such as the Honda Sensing Elite, are introduced into the market. With conditional or high automation, drivers will no longer be required to actively monitor the driving environment and can potentially engage in non-driving-related tasks. -->

{::nomarkdown}
		<div class="main-topic">
			<div class="right-text">
				<!-- <img src="images/Research/Investigation copy.png"> -->
				<!-- <p> -->
<UL>
<!-- <li>Du et al. (2020). Physiological responses to takeover requests in conditionally automated driving. Accident & Analysis Prevention. <a href="http://doi.org/10.1016/j.aap.2020.105804">[PDF]</a> </li>
<li>Du et al. (2020). Examining the effects of emotional valence and arousal on takeover performance in conditionally automated driving. Transportation Research Part C: Emerging Technologies.  <a href="http://doi.org/10.1016/j.trc.2020.01.006">[PDF]</a> </li>
<li>Du et al. (2020). Evaluating Effects of Cognitive Load, Takeover Request Lead Time, and Traffic Density on Drivers' Takeover Performance in Conditionally Automated Driving. Automotive UI 2020.  <a href="http://doi.org/10.1145/3409120.3410666">[PDF]</a>  <a href="https://www.youtube.com/watch?v=F34DHjgcn2I">[Video]</a> </li> -->
<!-- <li>Du et al. (2020). Examining effects of scenario type and vehicle speed on takeover readiness and performance in conditionally automated driving. HFES 2020. <a href="https://doi.org/10.1177/1071181320641482">[PDF]</a>  <a href="https://www.youtube.com/watch?v=Ln4pPmwiI9M">[Video]</a> </li> -->
<!-- </UL> -->
				<!-- </p> -->
			</div>
  			<div class="left-picture">
				<img src="images/Research/Investigation copy.png">
			</div>
  </div>

{:/}

<p>&nbsp;</p>
<p>&nbsp;</p>


<!-- {::nomarkdown}
<img src="images/Research/sensors.jpg" class="textwrapper__image">
{:/}
- Du et al. (2020). Physiological responses to takeover requests in conditionally automated driving. Accident & Analysis Prevention. 
- Du et al. (2020). Examining the effects of emotional valence and arousal on takeover performance in conditionally automated driving. Transportation Research Part C: Emerging Technologies. [PDF]
- Du et al. (2020). Evaluating Effects of Cognitive Load, Takeover Request Lead Time, and Traffic Density on Drivers' Takeover Performance in Conditionally Automated Driving. Automotive UI 2020. [PDF] [Video]
- Du et al. (2020). Examining effects of scenario type and vehicle speed on takeover readiness and performance in conditionally automated driving. HFES 2020. [Video]
 -->




---
## Human-Robot Interaction {#bm2}
<p></p>
We model human behaviors and design interaction systems for Human-Robot Interaction (HRI) in diverse settings, including manufacturing and daily life environments. Guided by human-centered design principles, we employ an iterative process to understand user needs, model human states, and design, prototype, and evaluate interaction technologies that facilitate effective communication between users and robotic systems. Our research aims to improve productivity and quality of life by making tasks such as mobility, navigation, and collaborative work more efficient and accessible. For example, we design robotic interfaces for manufacturing workers and wheelchair users.



{::nomarkdown}
		<div class="main-topic">
			<div class="right-text">
				<p>
<UL>

</UL>
				</p>
			</div>
  			<div class="left-picture">
				<img src="images/Research/wheelchair-robot.png">
			</div>
  </div>

{:/}

<p>&nbsp;</p>
<p>&nbsp;</p>





---
## Human Behavior Modeling {#bm3}
<p></p>
We use both data-driven methods and cognitive architecture to model dynamic human behaviors and mental states in cyber-physical systems. By leveraging models and methods from both human factors and machine learning, we develop computational models that are capable of predicting or inferring human behaviors when they interact with technologies. The inputs of models can be text, video, physiological data, etc. For example, we develop computational models to predict driver takeover performance in conditionally automated driving and situational awareness in highly automated driving. We use large-scale naturalistic driving datasets and crash databases to model real-world driver bahaviors and improve driving safety. 



{::nomarkdown}
		<div class="main-topic">
			<div class="right-text">
				<p>
<UL>
<!-- <li>Ayoub, J.*, Du, N.*, Yang, X. J., & Zhou, F. (2022). Predicting driver takeover time in conditionally automated driving. IEEE Transactions on Intelligent Transportation Systems. (*Equal contribution). <a href="https://doi.org/10.1109/TITS.2022.3154329">[PDF]</a> </li>
<li>Du, N., Zhou, F., Pulver E., Tilbury, D. M., Robert, L. P., Pradhan, A. K., & Yang, X. J. (2020). Predicting driver takeover performance in  conditionally  automated  driving. Accident & Analysis Prevention. <a href="http://doi.org/10.1016/j.aap.2020.105748">[PDF]</a> </li>
<li>Du, N., Zhou, F., Pulver E., Tilbury, D. M., Robert, L. P., Pradhan, A. K., & Yang, X. J. (2020). Predicting Takeover Performance in Conditionally Automated Driving. CHI 2020. <a href="http://doi.org/10.1145/3334480.3382963">[PDF]</a> </li> -->
</UL>
				</p>
			</div>
  			<div class="left-picture">
				<img src="images/Research/Modeling.jpg">
			</div>
  </div>

{:/}

<p>&nbsp;</p>
<p>&nbsp;</p>




---
## Trust and Situational Awareness in Human-Automation Teaming {#bm4}
<p></p>

Advances in artificial intelligence (AI) and machine learning are powering a new generation of intelligent systems. However, as these systems grow more complex, human operators often perceive them as black boxes, leading to gaps in situational awareness and inappropriate levels of trust, which hinder effective collaboration. To address these challenges, our research models user dynamics in trust and situational awareness, and designs and evaluates interfaces that enhance transparency through diverse information types, timing, and modalities. By improving system transparency, we aim to help users build appropriate trust, make informed decisions, and collaborate more effectively with intelligent systems. Application domains include automated vehicles, drones, robots, automated decision aids (e.g., military operations and medical diagnosis), and general algorithms.


 
<!-- {::nomarkdown}
		<div class="main-topic">
			<div class="right-text">
				<p>
<UL>
<li>Du, N., Robert, L., & Yang, X. J. (2022). A Cross-cultural Investigation of the Effects of Explanations on Drivers’ Trust, Preference, and Anxiety in Highly Automated Vehicles. Transportation Research Record.  <a href="https://doi.org/10.1177/03611981221100528">[PDF]</a> </li>
<li>Du, N., Haspiel, J., Zhang, Q., Tilbury, D., Pradhan, A. K., Yang, X. J., & Robert Jr, L. P. (2019). Look who’s talking now: Implications of AV’s explanations on driver’s trust, AV preference, anxiety and mental workload. Transportation Research Part C.  <a href="http://doi.org/10.1016/j.trc.2019.05.025">[PDF]</a> </li>
<li>Haspiel, J., Du, N., Yang, X. J., Tilbury, D., Pradhan, A., Robert, L. P., (2018). Explanations and Expectations: Trust Building in Automated Vehicles. HRI 2018.  <a href="http://doi.org/10.1145/3173386.3177057">[PDF]</a> </li> 
<li>Zhang, Q., Du, N., Yang, X. J., & Robert, L. (2018). Trust in AVs: The Impact of Expectations and Individual Differences. The Conference on Autonomous Vehicles in Society <a href="https://deepblue.lib.umich.edu/bitstream/handle/2027.42/142567/Zhang%20et%20al.%202018.pdf?sequence=1">[PDF]</a> </li>
</UL>
				</p>
			</div>
  			<div class="left-picture">
				<img src="images/Research/ExplanationsTrust.png">
			</div>
  </div>

{:/}
 -->


<p>&nbsp;</p>
<p>&nbsp;</p>

<!-- 
{::nomarkdown}
		<div class="main-topic">
			<div class="right-text">
				<p>
<UL>
<li>Du, N., Huang, K., Yang, X. J. (2019). Not all information is equal: Effects of disclosing likelihood information on trust, compliance and reliance, and task performance in human-automation teaming. Human Factors. <a href="http://doi.org/10.1177/0018720819862916">[PDF]</a> </li>
<li>Du N., Zhang Q., & Yang, X. J. (2018). Effects of automation reliability and reliability information on trust, dependence and dual-task performance. HFES 2018. <a href="http://doi.org/10.1177/1541931218621041">[PDF]</a> </li>
</UL>
				</p>
			</div>
  			<div class="left-picture">
				<img src="images/Research/SDT0.png">
			</div>
  </div>

{:/}


<p>&nbsp;</p>
<p>&nbsp;</p>


{::nomarkdown}
		<div class="main-topic">
			<div class="right-text">
				<p>
<UL>
<li>Luo, R., Du, N., & Yang, X. J. (2022). Enhancing autonomy transparency: an option-centric rationale approach. International Journal of Human-Computer Interaction. <a href="https://doi.org/10.1080/10447318.2022.2097602">[PDF]</a></li>
</UL>
				</p>
			</div>
  			<div class="left-picture">
				<img src="images/Research/with_exp_new.png">
			</div>
  </div>

{:/}


<p>&nbsp;</p>
<p>&nbsp;</p> -->




<!-- <img src="images/Research/SDT1.png" align="left" width="20%"> -->



<!-- 
## XX
XX.
<a role="button" href="./research_topics/XX" class="btn btn-success btn-sm">More details</a>
 -->

